{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8277f73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:01:12.101898Z",
     "iopub.status.busy": "2024-04-23T16:01:12.101545Z",
     "iopub.status.idle": "2024-04-23T16:01:28.797947Z",
     "shell.execute_reply": "2024-04-23T16:01:28.796887Z"
    },
    "papermill": {
     "duration": 16.708654,
     "end_time": "2024-04-23T16:01:28.800485",
     "exception": false,
     "start_time": "2024-04-23T16:01:12.091831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/seqeval/\r\n",
      "Processing /kaggle/input/seqeval/seqeval-1.2.2.tar.gz (from -r /kaggle/input/seqeval/requirements.txt (line 1))\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval->-r /kaggle/input/seqeval/requirements.txt (line 1)) (1.26.4)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval->-r /kaggle/input/seqeval/requirements.txt (line 1)) (1.2.2)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->-r /kaggle/input/seqeval/requirements.txt (line 1)) (1.11.4)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->-r /kaggle/input/seqeval/requirements.txt (line 1)) (1.4.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->-r /kaggle/input/seqeval/requirements.txt (line 1)) (3.2.0)\r\n",
      "Building wheels for collected packages: seqeval\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=a2c62ff892b1ce6e175ea406d86680b9d74779c3961eb8173210c1dd47d54826\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/be/6d/82/87acaf836bed90667f77936325c0a4b631944650898dee7802\r\n",
      "Successfully built seqeval\r\n",
      "Installing collected packages: seqeval\r\n",
      "Successfully installed seqeval-1.2.2\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --no-index --find-links '/kaggle/input/seqeval/' -r '/kaggle/input/seqeval/requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4f526eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:01:28.819157Z",
     "iopub.status.busy": "2024-04-23T16:01:28.818876Z",
     "iopub.status.idle": "2024-04-23T16:01:36.459244Z",
     "shell.execute_reply": "2024-04-23T16:01:36.458177Z"
    },
    "papermill": {
     "duration": 7.652378,
     "end_time": "2024-04-23T16:01:36.461823",
     "exception": false,
     "start_time": "2024-04-23T16:01:28.809445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import inspect\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from contextlib import nullcontext\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "from seqeval.metrics import recall_score, precision_score, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f164fdb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:01:36.481229Z",
     "iopub.status.busy": "2024-04-23T16:01:36.480766Z",
     "iopub.status.idle": "2024-04-23T16:01:37.804856Z",
     "shell.execute_reply": "2024-04-23T16:01:37.804010Z"
    },
    "papermill": {
     "duration": 1.336231,
     "end_time": "2024-04-23T16:01:37.807433",
     "exception": false,
     "start_time": "2024-04-23T16:01:36.471202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "eval_iters = 50\n",
    "iter_num = 0\n",
    "## training params\n",
    "n_embd = 768\n",
    "n_hidden  = n_embd*2\n",
    "gradient_accumulation_steps = 8 # to simulate a larger batch size\n",
    "batch_size = 4\n",
    "k_random = 20\n",
    "# micro step if gradient_accumulation_steps > 0 \n",
    "dropout = .1\n",
    "# optimizer\n",
    "learning_rate = 2e-5\n",
    "decay_lr = True \n",
    "lr_decay_iters = 650 # make equal to max_iters usually\n",
    "min_lr = 1e-6 # learning_rate / 10 usually\n",
    "warmup_iters = 10 #\n",
    "max_iters = 650 \n",
    "betas = (0.9,0.99)\n",
    "weight_decay = .01\n",
    "grad_clip = 1.0\n",
    "\n",
    "# ctx\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device == 'cpu' else torch.amp.autocast(device_type=device, dtype=ptdtype)\n",
    "\n",
    "# base model\n",
    "model_checkpoint = '/kaggle/input/debertav3base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f4324ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:01:37.827698Z",
     "iopub.status.busy": "2024-04-23T16:01:37.826772Z",
     "iopub.status.idle": "2024-04-23T16:01:40.633838Z",
     "shell.execute_reply": "2024-04-23T16:01:40.633013Z"
    },
    "papermill": {
     "duration": 2.81935,
     "end_time": "2024-04-23T16:01:40.636147",
     "exception": false,
     "start_time": "2024-04-23T16:01:37.816797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_json('/kaggle/input/pii-detection-removal-from-educational-data/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b6b105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:01:40.654178Z",
     "iopub.status.busy": "2024-04-23T16:01:40.653909Z",
     "iopub.status.idle": "2024-04-23T16:01:40.660499Z",
     "shell.execute_reply": "2024-04-23T16:01:40.659657Z"
    },
    "papermill": {
     "duration": 0.017722,
     "end_time": "2024-04-23T16:01:40.662512",
     "exception": false,
     "start_time": "2024-04-23T16:01:40.644790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def converttokenstodebert(sample,test=False):\n",
    "    new_tokens = []\n",
    "    new_labels = []\n",
    "    mask = []\n",
    "    for i,t in enumerate(tokenizer(sample.tokens)['input_ids']):\n",
    "        if t==[]:\n",
    "            continue\n",
    "        new_tokens.extend(t[1:-1])\n",
    "        mask.extend([i]*(len(t)-2))\n",
    "        if not test:\n",
    "            new_labels.extend([sample.labels[i]]*(len(t)-2))\n",
    "    \n",
    "    if test:\n",
    "        return [new_tokens,mask] \n",
    "    else:\n",
    "        return [new_tokens,new_labels,mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "023bb42c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:01:40.680230Z",
     "iopub.status.busy": "2024-04-23T16:01:40.679949Z",
     "iopub.status.idle": "2024-04-23T16:04:30.840650Z",
     "shell.execute_reply": "2024-04-23T16:04:30.839651Z"
    },
    "papermill": {
     "duration": 170.172256,
     "end_time": "2024-04-23T16:04:30.843142",
     "exception": false,
     "start_time": "2024-04-23T16:01:40.670886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.loc[:,['new_tokens','new_labels','mask']] = pd.DataFrame(data.apply(lambda x: converttokenstodebert(x),axis=1).tolist()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ec63911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:04:30.862626Z",
     "iopub.status.busy": "2024-04-23T16:04:30.862083Z",
     "iopub.status.idle": "2024-04-23T16:04:30.925471Z",
     "shell.execute_reply": "2024-04-23T16:04:30.924593Z"
    },
    "papermill": {
     "duration": 0.074551,
     "end_time": "2024-04-23T16:04:30.927470",
     "exception": false,
     "start_time": "2024-04-23T16:04:30.852919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the set of unique labels in the train dataset\n",
    "unique_labels = set()\n",
    "for i in data['new_labels'].apply(lambda x: set(x)):\n",
    "    unique_labels = unique_labels.union(i)\n",
    "unique_labels = list(unique_labels)\n",
    "unique_labels.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "688b3319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:04:30.945565Z",
     "iopub.status.busy": "2024-04-23T16:04:30.945267Z",
     "iopub.status.idle": "2024-04-23T16:04:31.378082Z",
     "shell.execute_reply": "2024-04-23T16:04:31.377025Z"
    },
    "papermill": {
     "duration": 0.444682,
     "end_time": "2024-04-23T16:04:31.380565",
     "exception": false,
     "start_time": "2024-04-23T16:04:30.935883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "      <th>new_tokens</th>\n",
       "      <th>new_labels</th>\n",
       "      <th>mask</th>\n",
       "      <th>Has_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "      <td>[2169, 12103, 270, 3513, 28310, 4593, 341, 737...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-NAME_STUDENT,...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 10, 12, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "      <td>[4941, 60488, 2169, 12103, 28525, 51146, 9395,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "      <td>[0, 1, 3, 4, 5, 7, 8, 10, 11, 12, 14, 15, 16, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
       "      <td>[16514, 568, 293, 102829, 44365, 22496, 6738, ...</td>\n",
       "      <td>[O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, I-NA...</td>\n",
       "      <td>[0, 1, 3, 4, 5, 5, 7, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
       "      <td>[2169, 12103, 270, 8432, 63632, 608, 3365, 260...</td>\n",
       "      <td>[O, O, O, O, B-NAME_STUDENT, B-NAME_STUDENT, I...</td>\n",
       "      <td>[0, 1, 2, 3, 5, 5, 6, 6, 8, 8, 9, 11, 12, 14, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
       "      <td>[28525, 877, 51146, 45730, 22543, 293, 877, 51...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-NAME_STUDENT, I-NAME_S...</td>\n",
       "      <td>[0, 1, 3, 5, 7, 9, 10, 12, 13, 15, 16, 18, 20,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                          full_text  \\\n",
       "0         7  Design Thinking for innovation reflexion-Avril...   \n",
       "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
       "3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
       "4        56  Assignment:  Visualization Reflection  Submitt...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "\n",
       "                                 trailing_whitespace  \\\n",
       "0  [True, True, True, True, False, False, True, F...   \n",
       "1  [True, False, False, True, True, False, False,...   \n",
       "2  [True, False, False, True, True, False, False,...   \n",
       "3  [True, True, True, False, False, True, False, ...   \n",
       "4  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...   \n",
       "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...   \n",
       "2  [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...   \n",
       "3  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...   \n",
       "\n",
       "                                          new_tokens  \\\n",
       "0  [2169, 12103, 270, 3513, 28310, 4593, 341, 737...   \n",
       "1  [4941, 60488, 2169, 12103, 28525, 51146, 9395,...   \n",
       "2  [16514, 568, 293, 102829, 44365, 22496, 6738, ...   \n",
       "3  [2169, 12103, 270, 8432, 63632, 608, 3365, 260...   \n",
       "4  [28525, 877, 51146, 45730, 22543, 293, 877, 51...   \n",
       "\n",
       "                                          new_labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, B-NAME_STUDENT,...   \n",
       "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...   \n",
       "2  [O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, I-NA...   \n",
       "3  [O, O, O, O, B-NAME_STUDENT, B-NAME_STUDENT, I...   \n",
       "4  [O, O, O, O, O, O, O, B-NAME_STUDENT, I-NAME_S...   \n",
       "\n",
       "                                                mask  Has_label  \n",
       "0  [0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10, 10, 12, ...       True  \n",
       "1  [0, 1, 3, 4, 5, 7, 8, 10, 11, 12, 14, 15, 16, ...       True  \n",
       "2  [0, 1, 3, 4, 5, 5, 7, 9, 10, 11, 12, 13, 14, 1...       True  \n",
       "3  [0, 1, 2, 3, 5, 5, 6, 6, 8, 8, 9, 11, 12, 14, ...       True  \n",
       "4  [0, 1, 3, 5, 7, 9, 10, 12, 13, 15, 16, 18, 20,...       True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the samples that have some target in the labels.\n",
    "data = data.assign(Has_label = data.apply(lambda x: False in ['O'==i for i in x['new_labels']],axis=1))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ddd2a42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:04:31.400190Z",
     "iopub.status.busy": "2024-04-23T16:04:31.399845Z",
     "iopub.status.idle": "2024-04-23T16:04:31.414861Z",
     "shell.execute_reply": "2024-04-23T16:04:31.413814Z"
    },
    "papermill": {
     "duration": 0.027195,
     "end_time": "2024-04-23T16:04:31.416908",
     "exception": false,
     "start_time": "2024-04-23T16:04:31.389713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data,test_size=0.1, stratify=data['Has_label'], random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58e84f69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:04:31.436560Z",
     "iopub.status.busy": "2024-04-23T16:04:31.436144Z",
     "iopub.status.idle": "2024-04-23T16:04:31.458683Z",
     "shell.execute_reply": "2024-04-23T16:04:31.457857Z"
    },
    "papermill": {
     "duration": 0.034692,
     "end_time": "2024-04-23T16:04:31.460779",
     "exception": false,
     "start_time": "2024-04-23T16:04:31.426087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self,model_checkpoint):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_checkpoint = AutoModelForTokenClassification.from_pretrained(model_checkpoint).deberta\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.clf = nn.Linear(n_embd,len(unique_labels))\n",
    "        self.filter_ = torch.tensor([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],requires_grad=False).to(device) # 'O' target\n",
    "\n",
    "\n",
    "    def forward(self,x,targets=None,k_random=None):\n",
    "        \n",
    "        x = self.model_checkpoint(**x).last_hidden_state\n",
    "        x = self.dropout(x)\n",
    "        logits = self.clf(x)\n",
    "        \n",
    "        logits = logits.softmax(dim=-1)\n",
    "        \n",
    "        # training\n",
    "        if targets is not None:\n",
    "            # Identify the positions in the logits sequence that predict a target.\n",
    "            mask_logits = logits.argmax(-1)!=12\n",
    "\n",
    "            # do the same with the label sequence.\n",
    "            mask_targets = torch.sum(targets!=self.filter_,-1)!=0\n",
    "\n",
    "            # for the first 250 iterations, the cost function is applied to targets predicted by the model and the actual ones.\n",
    "            if iter_num<250:\n",
    "                mask = mask_targets+mask_logits\n",
    "                # after 150 iterations, negative predictions are also being added.\n",
    "                if np.random.rand() > 0.5 and iter_num >150:\n",
    "                    random_positions = torch.randint(0,mask.shape[1],(iter_num//k_random,1))\n",
    "                    mask[:,random_positions]=True\n",
    "            else:\n",
    "                # combine the two masks\n",
    "                mask = mask_targets+mask_logits\n",
    "                # add extra random tokens\n",
    "                random_positions = torch.randint(0,mask.shape[1],(iter_num//k_random,1))\n",
    "                mask[:,random_positions]=True\n",
    "\n",
    "            logits = logits[mask]\n",
    "            targets= targets[mask]\n",
    "            \n",
    "            loss = F.cross_entropy(logits,targets)\n",
    "        \n",
    "        # inference\n",
    "        else:\n",
    "            loss=None\n",
    "            mask=None\n",
    "            \n",
    "        return logits, loss, mask\n",
    "\n",
    "    def configure_optimizers(self,weight_decay, learning_rate, betas, device_type):\n",
    "\n",
    "        # the parameters to which regularization is applied are separated.\n",
    "        decay = set()\n",
    "        no_decay = set()\n",
    "        whitelist_weight_modules = (nn.Linear,)\n",
    "        blacklist_weight_modules = (nn.LayerNorm, nn.Embedding)\n",
    "\n",
    "        for mn, m in self.named_modules():\n",
    "            for pn, p in m.named_parameters():\n",
    "                fpn = '%s.%s' % (mn,pn) if mn else pn\n",
    "\n",
    "                if pn.endswith('bias'):\n",
    "                    no_decay.add(fpn)\n",
    "                    continue\n",
    "                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n",
    "                    decay.add(fpn)\n",
    "                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
    "                    no_decay.add(fpn)\n",
    "\n",
    "        param_dict = {pn:p for pn, p in self.named_parameters()}\n",
    "        # validation\n",
    "        inter_params = decay & no_decay\n",
    "        union_params = decay | no_decay\n",
    "        assert len(inter_params) == 0, \"Los parámetros %s están en los dos conjuntos decay y no_decay!\" % str(inter_params)\n",
    "        assert len(param_dict.keys() - union_params) == 0, \"Los parámetros %s, no están en nungún conjunto decay/no_decay!\" % str(param_dict.keys() - union_params)\n",
    "\n",
    "        # optimization objects\n",
    "        optim_groups = [\n",
    "            {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\":weight_decay},\n",
    "            {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\":0.0}\n",
    "        ]\n",
    "        \n",
    "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
    "        use_fused = fused_available and device_type == 'cuda'\n",
    "        extra_args = dict(fused=True) if use_fused else dict()\n",
    "\n",
    "        optimizer = torch.optim.AdamW(optim_groups,lr=learning_rate,betas=betas)\n",
    "\n",
    "        return optimizer\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict(self,test):\n",
    "        self.eval()\n",
    "        preds = []\n",
    "        for i in tqdm(range(0,test.shape[0],batch_size)):\n",
    "            X = get_batch(test,test=True,i=i)\n",
    "            \n",
    "            logits,_,_ = self(X)\n",
    "            pred = logits.cpu().argmax(-1)\n",
    "            preds.append(pred)\n",
    "        \n",
    "        self.train()\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8105da82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:04:31.479798Z",
     "iopub.status.busy": "2024-04-23T16:04:31.479507Z",
     "iopub.status.idle": "2024-04-23T16:04:37.328462Z",
     "shell.execute_reply": "2024-04-23T16:04:37.327536Z"
    },
    "papermill": {
     "duration": 5.860908,
     "end_time": "2024-04-23T16:04:37.330400",
     "exception": false,
     "start_time": "2024-04-23T16:04:31.469492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at /kaggle/input/debertav3base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at /kaggle/input/debertav3base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (model_checkpoint): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (clf): Linear(in_features=768, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training model\n",
    "model = Classifier(model_checkpoint)\n",
    "model.to(device)\n",
    "\n",
    "# final model for inference\n",
    "best_model = Classifier(model_checkpoint)\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35c9b23e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:04:37.350002Z",
     "iopub.status.busy": "2024-04-23T16:04:37.349557Z",
     "iopub.status.idle": "2024-04-23T16:04:37.364716Z",
     "shell.execute_reply": "2024-04-23T16:04:37.363949Z"
    },
    "papermill": {
     "duration": 0.027593,
     "end_time": "2024-04-23T16:04:37.367241",
     "exception": false,
     "start_time": "2024-04-23T16:04:37.339648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize a GradScaler. If enabled=False scaler is a no-op\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
    "\n",
    "# optimizer\n",
    "optimizer = model.configure_optimizers(weight_decay, learning_rate, betas, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "090182a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:04:37.387292Z",
     "iopub.status.busy": "2024-04-23T16:04:37.386982Z",
     "iopub.status.idle": "2024-04-23T16:04:37.400155Z",
     "shell.execute_reply": "2024-04-23T16:04:37.399247Z"
    },
    "papermill": {
     "duration": 0.025593,
     "end_time": "2024-04-23T16:04:37.402128",
     "exception": false,
     "start_time": "2024-04-23T16:04:37.376535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data collator\n",
    "def get_batch(data,test=False,i=0):\n",
    "    \n",
    "    if not test:\n",
    "        MAX_LENGHT = 1024\n",
    "        # get random samples during training\n",
    "        # start adding negative labels after 200 iters\n",
    "        if iter_num<200:\n",
    "            batch = data.query('Has_label==1')[['new_tokens','new_labels']].sample(batch_size)\n",
    "        else:\n",
    "            \n",
    "            batch = data[['new_tokens','new_labels']].sample(batch_size) \n",
    "        MAX_INPUT_LENGHT = batch.new_tokens.apply(len).max()\n",
    "    else:\n",
    "        MAX_LENGHT=10000\n",
    "        # get samples in sequential order in inference\n",
    "        batch = data.iloc[i:i+batch_size][['new_tokens']]\n",
    "        MAX_INPUT_LENGHT = batch.new_tokens.apply(len).max()\n",
    "\n",
    "    # pad the lists to MAX_INPUT_LENGHT\n",
    "    input_ids = torch.Tensor(batch['new_tokens'].apply(lambda x: [1]+x+[2] + [0]*(MAX_INPUT_LENGHT - len(x))).tolist()[:MAX_LENGHT]).to(torch.long)\n",
    "    # mask attention\n",
    "    attention_mask = torch.Tensor(batch['new_tokens'].apply(lambda x: [1]*(len(x)+2) + [0]*(MAX_INPUT_LENGHT - len(x))).tolist()[:MAX_LENGHT]).to(torch.long)\n",
    "    # input fed into the model\n",
    "    X = {'input_ids':input_ids[:,:MAX_LENGHT].to(device),\n",
    "         'attention_mask':attention_mask[:,:MAX_LENGHT].to(device)}\n",
    "    if not test:\n",
    "        # convert the labels ['O','O',...] into one hot sparse lists [[0,0,1,0,..],[0,..]...]\n",
    "        y = batch['new_labels'].apply(lambda x: x + ['O']*(MAX_INPUT_LENGHT - len(x)))\n",
    "        y = y.apply(lambda x: [[0]*12+[1]] + [[0]*(unique_labels.index(l)+1-1)+[1]+(len(unique_labels)-unique_labels.index(l)-1)*[0] for l in x]+[[0]*12+[1]])\n",
    "        y = torch.Tensor(y.tolist())[:,:MAX_LENGHT].to(device)\n",
    "    \n",
    "        return X,y  # X format ~ {'input_ids':tensor(...),'att_mask':tensor(0,..)}\n",
    "    \n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "587d8112",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:04:37.422277Z",
     "iopub.status.busy": "2024-04-23T16:04:37.421990Z",
     "iopub.status.idle": "2024-04-23T16:04:37.427548Z",
     "shell.execute_reply": "2024-04-23T16:04:37.426610Z"
    },
    "papermill": {
     "duration": 0.017887,
     "end_time": "2024-04-23T16:04:37.429485",
     "exception": false,
     "start_time": "2024-04-23T16:04:37.411598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# learning rate warmup with cosine decay\n",
    "def get_lr(it):\n",
    "    # 1) linear warmup for the first warmup_iters steps\n",
    "    if it < warmup_iters:\n",
    "        return learning_rate #* it / warmup_iters\n",
    "    # 2) if it > lr_decay_iters, return min learning rate\n",
    "    if it > lr_decay_iters:\n",
    "        return min_lr\n",
    "    # 3) in between, use cosine decay down to min learning rate\n",
    "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff ranges 0..1\n",
    "    return min_lr + coeff * (learning_rate - min_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c59e3b8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:04:37.449193Z",
     "iopub.status.busy": "2024-04-23T16:04:37.448949Z",
     "iopub.status.idle": "2024-04-23T16:04:37.459699Z",
     "shell.execute_reply": "2024-04-23T16:04:37.458760Z"
    },
    "papermill": {
     "duration": 0.022694,
     "end_time": "2024-04-23T16:04:37.461708",
     "exception": false,
     "start_time": "2024-04-23T16:04:37.439014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## evaluation function\n",
    "np.seterr(invalid='ignore')\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        recall = torch.zeros(eval_iters)\n",
    "        precision = torch.zeros(eval_iters)\n",
    "        f1_scores = torch.zeros(eval_iters)\n",
    "        for k in tqdm(range(eval_iters), ascii=True, desc=split):\n",
    "            X,Y = get_batch(data_train) if split=='train' else get_batch(data_test)\n",
    "            with ctx:\n",
    "                logits, loss, mask = model(X,Y,k_random)\n",
    "            losses[k] = loss.item()\n",
    "            # f5 score\n",
    "            predictions = (pd.Series(logits.cpu().argmax(-1).tolist())\n",
    "                           .apply(lambda x: unique_labels[x])\n",
    "                           .tolist()\n",
    "                          )\n",
    "            \n",
    "            y_true = (pd.Series(Y[mask].cpu().argmax(-1).tolist())\n",
    "                           .apply(lambda x: unique_labels[x])\n",
    "                           .tolist()\n",
    "                     )\n",
    "            \n",
    "            recall[k] = recall_score([predictions],[y_true],zero_division=0)\n",
    "            precision[k] = precision_score([predictions], [y_true],zero_division=0)\n",
    "            f1_scores[k] = (1 + 5*5) * recall[k] * precision[k] / (5*5*precision[k] + recall[k])\n",
    "        out[split] = np.nanmean(losses)\n",
    "        out[split+'_precision'] = torch.mean(precision)\n",
    "        out[split+'_recall'] = torch.mean(recall)\n",
    "        out[split+'_pred_f'] = np.nanmean(f1_scores)\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50d35197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:04:37.481176Z",
     "iopub.status.busy": "2024-04-23T16:04:37.480930Z",
     "iopub.status.idle": "2024-04-23T16:37:53.062077Z",
     "shell.execute_reply": "2024-04-23T16:37:53.061248Z"
    },
    "papermill": {
     "duration": 1995.593765,
     "end_time": "2024-04-23T16:37:53.064388",
     "exception": false,
     "start_time": "2024-04-23T16:04:37.470623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:16<00:00,  3.07it/s]\n",
      "val: 100%|##########| 50/50 [00:15<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 2.4943,train f1 0.0070, \n",
      "            val loss 2.4972, val precision 0.0004, val recall 0.0000, val f1 0.0020, learning rate 0.2000\n",
      "\n",
      "Iter 0: Loss: 0.3119,\n",
      "Iter 1: Loss: 0.3106,\n",
      "Iter 2: Loss: 0.3108,\n",
      "Iter 3: Loss: 0.3133,\n",
      "Iter 4: Loss: 0.3150,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.50it/s]\n",
      "val: 100%|##########| 50/50 [00:14<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5: train loss 2.6038,train f1 nan, \n",
      "            val loss 2.6164, val precision 0.0000, val recall 0.0000, val f1 nan, learning rate 0.2000\n",
      "\n",
      "Iter 5: Loss: 0.3168,\n",
      "Iter 6: Loss: 0.3178,\n",
      "Iter 7: Loss: 0.3173,\n",
      "Iter 8: Loss: 0.3172,\n",
      "Iter 9: Loss: 0.3177,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.49it/s]\n",
      "val: 100%|##########| 50/50 [00:14<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10: train loss 2.5682,train f1 nan, \n",
      "            val loss 2.5669, val precision 0.0000, val recall 0.0000, val f1 nan, learning rate 0.2000\n",
      "\n",
      "Iter 10: Loss: 0.3184,\n",
      "Iter 11: Loss: 0.3188,\n",
      "Iter 12: Loss: 0.3188,\n",
      "Iter 13: Loss: 0.3177,\n",
      "Iter 14: Loss: 0.3166,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.41it/s]\n",
      "val: 100%|##########| 50/50 [00:15<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 15: train loss 2.4950,train f1 0.4925, \n",
      "            val loss 2.4770, val precision 0.0032, val recall 0.0800, val f1 0.3354, learning rate 0.2000\n",
      "\n",
      "Iter 15: Loss: 0.3146,\n",
      "Iter 16: Loss: 0.3122,\n",
      "Iter 17: Loss: 0.3117,\n",
      "Iter 18: Loss: 0.3115,\n",
      "Iter 19: Loss: 0.3098,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.45it/s]\n",
      "val: 100%|##########| 50/50 [00:15<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20: train loss 2.4368,train f1 0.3300, \n",
      "            val loss 2.3960, val precision 0.1980, val recall 0.3226, val f1 0.4606, learning rate 0.1999\n",
      "\n",
      "Iter 20: Loss: 0.3079,\n",
      "Iter 21: Loss: 0.3067,\n",
      "Iter 22: Loss: 0.3053,\n",
      "Iter 23: Loss: 0.3038,\n",
      "Iter 24: Loss: 0.3025,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.49it/s]\n",
      "val: 100%|##########| 50/50 [00:14<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 25: train loss 2.3507,train f1 0.2229, \n",
      "            val loss 2.3398, val precision 0.2440, val recall 0.2231, val f1 0.2513, learning rate 0.1997\n",
      "\n",
      "Iter 25: Loss: 0.3012,\n",
      "Iter 26: Loss: 0.3004,\n",
      "Iter 27: Loss: 0.2973,\n",
      "Iter 28: Loss: 0.2947,\n",
      "Iter 29: Loss: 0.2938,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.37it/s]\n",
      "val: 100%|##########| 50/50 [00:15<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 30: train loss 2.3018,train f1 0.3455, \n",
      "            val loss 2.2618, val precision 0.4185, val recall 0.3865, val f1 0.3993, learning rate 0.1995\n",
      "\n",
      "Iter 30: Loss: 0.2927,\n",
      "Iter 31: Loss: 0.2904,\n",
      "Iter 32: Loss: 0.2905,\n",
      "Iter 33: Loss: 0.2894,\n",
      "Iter 34: Loss: 0.2886,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.45it/s]\n",
      "val: 100%|##########| 50/50 [00:15<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 35: train loss 2.2242,train f1 0.4505, \n",
      "            val loss 2.2099, val precision 0.5324, val recall 0.4146, val f1 0.4204, learning rate 0.1993\n",
      "\n",
      "Iter 35: Loss: 0.2895,\n",
      "Iter 36: Loss: 0.2896,\n",
      "Iter 37: Loss: 0.2866,\n",
      "Iter 38: Loss: 0.2859,\n",
      "Iter 39: Loss: 0.2849,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.45it/s]\n",
      "val: 100%|##########| 50/50 [00:14<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 40: train loss 2.1163,train f1 0.6297, \n",
      "            val loss 2.0452, val precision 0.8315, val recall 0.7379, val f1 0.7374, learning rate 0.1990\n",
      "\n",
      "Iter 40: Loss: 0.2828,\n",
      "Iter 41: Loss: 0.2856,\n",
      "Iter 42: Loss: 0.2816,\n",
      "Iter 43: Loss: 0.2817,\n",
      "Iter 44: Loss: 0.2768,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.38it/s]\n",
      "val: 100%|##########| 50/50 [00:14<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 45: train loss 2.0250,train f1 0.7086, \n",
      "            val loss 2.0019, val precision 0.8614, val recall 0.7354, val f1 0.7364, learning rate 0.1986\n",
      "\n",
      "Iter 45: Loss: 0.2713,\n",
      "Iter 46: Loss: 0.2685,\n",
      "Iter 47: Loss: 0.2709,\n",
      "Iter 48: Loss: 0.2661,\n",
      "Iter 49: Loss: 0.2629,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.35it/s]\n",
      "val: 100%|##########| 50/50 [00:14<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 50: train loss 1.9524,train f1 0.7569, \n",
      "            val loss 1.9055, val precision 0.8104, val recall 0.8484, val f1 0.8440, learning rate 0.1982\n",
      "\n",
      "Iter 50: Loss: 0.2634,\n",
      "Iter 51: Loss: 0.2562,\n",
      "Iter 52: Loss: 0.2579,\n",
      "Iter 53: Loss: 0.2546,\n",
      "Iter 54: Loss: 0.2566,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.47it/s]\n",
      "val: 100%|##########| 50/50 [00:15<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 55: train loss 1.9191,train f1 0.7589, \n",
      "            val loss 1.8492, val precision 0.8637, val recall 0.8374, val f1 0.8371, learning rate 0.1977\n",
      "\n",
      "Iter 55: Loss: 0.2540,\n",
      "Iter 56: Loss: 0.2546,\n",
      "Iter 57: Loss: 0.2498,\n",
      "Iter 58: Loss: 0.2515,\n",
      "Iter 59: Loss: 0.2514,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.35it/s]\n",
      "val: 100%|##########| 50/50 [00:14<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 60: train loss 1.9023,train f1 0.7931, \n",
      "            val loss 1.8482, val precision 0.8213, val recall 0.8575, val f1 0.8539, learning rate 0.1972\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 681/681 [00:38<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 60, precision: 0.8039702233250621, recall: 0.5567010309278351, f5: 0.5633652109944491\n",
      "Model checkpoint\n",
      "Iter 60: Loss: 0.2489,\n",
      "Iter 61: Loss: 0.2469,\n",
      "Iter 62: Loss: 0.2427,\n",
      "Iter 63: Loss: 0.2426,\n",
      "Iter 64: Loss: 0.2426,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.55it/s]\n",
      "val: 100%|##########| 50/50 [00:15<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 65: train loss 1.8726,train f1 0.8175, \n",
      "            val loss 1.8613, val precision 0.7843, val recall 0.8567, val f1 0.8409, learning rate 0.1966\n",
      "\n",
      "Iter 65: Loss: 0.2431,\n",
      "Iter 66: Loss: 0.2443,\n",
      "Iter 67: Loss: 0.2436,\n",
      "Iter 68: Loss: 0.2399,\n",
      "Iter 69: Loss: 0.2365,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.36it/s]\n",
      "val: 100%|##########| 50/50 [00:14<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 70: train loss 1.9813,train f1 0.8096, \n",
      "            val loss 1.8604, val precision 0.8233, val recall 0.9069, val f1 0.8970, learning rate 0.1959\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 681/681 [00:38<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 70, precision: 0.6972704714640199, recall: 0.7113924050632912, f5: 0.7108386845689824\n",
      "Model checkpoint\n",
      "Iter 70: Loss: 0.2332,\n",
      "Iter 71: Loss: 0.2333,\n",
      "Iter 72: Loss: 0.2313,\n",
      "Iter 73: Loss: 0.2283,\n",
      "Iter 74: Loss: 0.2235,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.44it/s]\n",
      "val: 100%|##########| 50/50 [00:14<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 75: train loss 1.8395,train f1 0.8149, \n",
      "            val loss 1.7954, val precision 0.9129, val recall 0.8904, val f1 0.8899, learning rate 0.1952\n",
      "\n",
      "Iter 75: Loss: 0.2234,\n",
      "Iter 76: Loss: 0.2184,\n",
      "Iter 77: Loss: 0.2221,\n",
      "Iter 78: Loss: 0.2222,\n",
      "Iter 79: Loss: 0.2279,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.44it/s]\n",
      "val: 100%|##########| 50/50 [00:14<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 80: train loss 1.8645,train f1 0.7854, \n",
      "            val loss 1.7863, val precision 0.8981, val recall 0.9027, val f1 0.9018, learning rate 0.1944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 681/681 [00:38<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 80, precision: 0.8436724565756824, recall: 0.4207920792079208, f5: 0.429063728583216\n",
      "Iter 80: Loss: 0.2304,\n",
      "Iter 81: Loss: 0.2326,\n",
      "Iter 82: Loss: 0.2330,\n",
      "Iter 83: Loss: 0.2323,\n",
      "Iter 84: Loss: 0.2341,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.36it/s]\n",
      "val: 100%|##########| 50/50 [00:15<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 85: train loss 1.8221,train f1 0.8820, \n",
      "            val loss 1.8092, val precision 0.8469, val recall 0.9052, val f1 0.9020, learning rate 0.1936\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 681/681 [00:38<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 85, precision: 0.7617866004962779, recall: 0.5984405458089669, f5: 0.6034169942546114\n",
      "Iter 85: Loss: 0.2330,\n",
      "Iter 86: Loss: 0.2321,\n",
      "Iter 87: Loss: 0.2300,\n",
      "Iter 88: Loss: 0.2304,\n",
      "Iter 89: Loss: 0.2277,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:13<00:00,  3.61it/s]\n",
      "val: 100%|##########| 50/50 [00:14<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 90: train loss 1.8510,train f1 0.8403, \n",
      "            val loss 1.7809, val precision 0.9453, val recall 0.8990, val f1 0.8990, learning rate 0.1928\n",
      "\n",
      "Iter 90: Loss: 0.2251,\n",
      "Iter 91: Loss: 0.2291,\n",
      "Iter 92: Loss: 0.2287,\n",
      "Iter 93: Loss: 0.2327,\n",
      "Iter 94: Loss: 0.2310,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.46it/s]\n",
      "val: 100%|##########| 50/50 [00:14<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 95: train loss 1.8218,train f1 0.8705, \n",
      "            val loss 1.8415, val precision 0.8904, val recall 0.8287, val f1 0.8280, learning rate 0.1918\n",
      "\n",
      "Iter 95: Loss: 0.2313,\n",
      "Iter 96: Loss: 0.2302,\n",
      "Iter 97: Loss: 0.2304,\n",
      "Iter 98: Loss: 0.2357,\n",
      "Iter 99: Loss: 0.2387,\n",
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|##########| 50/50 [00:14<00:00,  3.45it/s]\n",
      "val: 100%|##########| 50/50 [00:15<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 100: train loss 1.8236,train f1 0.9048, \n",
      "            val loss 1.8396, val precision 0.8555, val recall 0.9185, val f1 0.9115, learning rate 0.1909\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 681/681 [00:38<00:00, 17.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 100, precision: 0.7890818858560794, recall: 0.6162790697674418, f5: 0.6215139442231075\n",
      "Iter 100: Loss: 0.2427,\n"
     ]
    }
   ],
   "source": [
    "X,Y = get_batch(data_train)\n",
    "best_f5_score = 0\n",
    "best_val_score = 0.85\n",
    "accuracy_bak = []\n",
    "loss_bak = []\n",
    "while True:\n",
    "    \n",
    "    lr = get_lr(iter_num) if decay_lr else learning_rate\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    # evaluation step \n",
    "    if iter_num % 5 ==0:\n",
    "        print('Evaluating...')\n",
    "        losses = estimate_loss()\n",
    "        print(f\"\"\"step {iter_num}: train loss {losses['train']:.4f},train f1 {losses['train_pred_f']:.4f}, \n",
    "            val loss {losses['val']:.4f}, val precision {losses['val_precision']:.4f}, val recall {losses['val_recall']:.4f}, val f1 {losses['val_pred_f']:.4f}, learning rate {lr*10**4:.4f}\\n\"\"\")\n",
    "        \n",
    "        if losses['val_pred_f'] > best_val_score or losses['val_pred_f'] > 0.97:\n",
    "            best_val_score = losses['val_pred_f']\n",
    "            ## Making predictions \n",
    "            batch_size = 1\n",
    "            \n",
    "            predictions = model.predict(data_test)\n",
    "            # return batch size\n",
    "            batch_size=4\n",
    "            \n",
    "            list_preds = []\n",
    "            for tensor in predictions:\n",
    "                for l in tensor.tolist():\n",
    "                    list_preds.extend([[unique_labels[i] for i in l]])\n",
    "            # calculating metrics              \n",
    "            recall = recall_score(list_preds,data_test.new_labels.apply(lambda x: ['O']+x+['O']).tolist(),zero_division=0)\n",
    "            precision = precision_score(list_preds,data_test.new_labels.apply(lambda x: ['O']+x+['O']).tolist(),zero_division=0)\n",
    "            f5_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n",
    "            print(f\"step: {iter_num}, precision: {precision}, recall: {recall}, f5: {f5_score}\")\n",
    "            \n",
    "            # save the best model\n",
    "            if f5_score > best_f5_score:\n",
    "                best_f5_score = f5_score\n",
    "                print(\"Model checkpoint\")\n",
    "                best_model.load_state_dict(model.state_dict())\n",
    "            \n",
    "            del predictions, list_preds\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    # one forward backward step with gradient accumulation to simulate larger batch size\n",
    "    for micro_step in range(gradient_accumulation_steps):\n",
    "\n",
    "        # forward step with autocast\n",
    "        with ctx:\n",
    "            _,loss,_ = model(X,Y,k_random)\n",
    "            loss = loss/gradient_accumulation_steps\n",
    "        \n",
    "        # remove X and Y from memory\n",
    "        del X, Y\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # get the batch for the next step     \n",
    "        X, Y = get_batch(data)\n",
    "        # backward step with GradScaler when training is in fp16 to prevent \"overflow\"\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "    # optional clip the gradients\n",
    "    if grad_clip != 0.0:\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        \n",
    "    # step the optimizer and scaler if training in fp16\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    # report loss train in each step\n",
    "    loss_bak.append(loss.cpu().detach().numpy())\n",
    "    # mean values of last 10 steps\n",
    "    print(f\"Iter {iter_num}: Loss: {np.nanmean(loss_bak[-10:]):.4f},\")\n",
    "    \n",
    "    iter_num +=1\n",
    "    \n",
    "    if iter_num == 101:\n",
    "        break\n",
    "        \n",
    "\n",
    "# delete training model, no needed anymore\n",
    "del model.model_checkpoint, model.clf, model, optimizer, scaler\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02e61434",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:37:53.662763Z",
     "iopub.status.busy": "2024-04-23T16:37:53.661850Z",
     "iopub.status.idle": "2024-04-23T16:38:32.570000Z",
     "shell.execute_reply": "2024-04-23T16:38:32.568952Z"
    },
    "papermill": {
     "duration": 39.210624,
     "end_time": "2024-04-23T16:38:32.572328",
     "exception": false,
     "start_time": "2024-04-23T16:37:53.361704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 681/681 [00:38<00:00, 17.60it/s]\n"
     ]
    }
   ],
   "source": [
    "## Making predictions\n",
    "batch_size = 1\n",
    "best_model.to(device)\n",
    "predictions = best_model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39252499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:38:33.274473Z",
     "iopub.status.busy": "2024-04-23T16:38:33.273632Z",
     "iopub.status.idle": "2024-04-23T16:38:33.323918Z",
     "shell.execute_reply": "2024-04-23T16:38:33.323046Z"
    },
    "papermill": {
     "duration": 0.422179,
     "end_time": "2024-04-23T16:38:33.325942",
     "exception": false,
     "start_time": "2024-04-23T16:38:32.903763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_preds = []\n",
    "for tensor in predictions:\n",
    "    for l in tensor.tolist():\n",
    "        list_preds.extend([[unique_labels[i] for i in l]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4d8e9f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:38:33.956860Z",
     "iopub.status.busy": "2024-04-23T16:38:33.956141Z",
     "iopub.status.idle": "2024-04-23T16:38:37.844732Z",
     "shell.execute_reply": "2024-04-23T16:38:37.843646Z"
    },
    "papermill": {
     "duration": 4.207458,
     "end_time": "2024-04-23T16:38:37.847022",
     "exception": false,
     "start_time": "2024-04-23T16:38:33.639564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.6972704714640199, recall: 0.7113924050632912, f5: 0.7108386845689824\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(list_preds,data_test.new_labels.apply(lambda x: ['O']+x+['O']).tolist(),zero_division=0)\n",
    "precision = precision_score(list_preds,data_test.new_labels.apply(lambda x: ['O']+x+['O']).tolist(),zero_division=0)\n",
    "f5_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n",
    "print(f\"precision: {precision}, recall: {recall}, f5: {f5_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0d720c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:38:38.491115Z",
     "iopub.status.busy": "2024-04-23T16:38:38.490514Z",
     "iopub.status.idle": "2024-04-23T16:38:38.535073Z",
     "shell.execute_reply": "2024-04-23T16:38:38.533990Z"
    },
    "papermill": {
     "duration": 0.366147,
     "end_time": "2024-04-23T16:38:38.537666",
     "exception": false,
     "start_time": "2024-04-23T16:38:38.171519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_json('/kaggle/input/pii-detection-removal-from-educational-data/test.json')\n",
    "submissions = pd.read_csv('/kaggle/input/pii-detection-removal-from-educational-data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f889101",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:38:39.209847Z",
     "iopub.status.busy": "2024-04-23T16:38:39.208912Z",
     "iopub.status.idle": "2024-04-23T16:38:39.305373Z",
     "shell.execute_reply": "2024-04-23T16:38:39.304531Z"
    },
    "papermill": {
     "duration": 0.420255,
     "end_time": "2024-04-23T16:38:39.307548",
     "exception": false,
     "start_time": "2024-04-23T16:38:38.887293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform test data\n",
    "test.loc[:,['new_tokens','mask']] = pd.DataFrame(test.apply(lambda x: converttokenstodebert(x,True),axis=1).tolist()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "916478b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:38:39.937056Z",
     "iopub.status.busy": "2024-04-23T16:38:39.936727Z",
     "iopub.status.idle": "2024-04-23T16:38:40.649078Z",
     "shell.execute_reply": "2024-04-23T16:38:40.648190Z"
    },
    "papermill": {
     "duration": 1.025816,
     "end_time": "2024-04-23T16:38:40.651253",
     "exception": false,
     "start_time": "2024-04-23T16:38:39.625437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 14.27it/s]\n"
     ]
    }
   ],
   "source": [
    "## Making predictions\n",
    "batch_size = 1\n",
    "predictions = best_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46def9b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:38:41.319540Z",
     "iopub.status.busy": "2024-04-23T16:38:41.319117Z",
     "iopub.status.idle": "2024-04-23T16:38:41.370306Z",
     "shell.execute_reply": "2024-04-23T16:38:41.369447Z"
    },
    "papermill": {
     "duration": 0.366365,
     "end_time": "2024-04-23T16:38:41.372356",
     "exception": false,
     "start_time": "2024-04-23T16:38:41.005991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>482</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>483</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>741</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>742</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>464</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>465</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Gilberto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Gamboa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Sindy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Samaca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>328</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>George</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>330</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Geoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nadine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Born</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Eladio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Amaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Silvia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Villalobos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Dr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>104</td>\n",
       "      <td>8</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Sakir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Ahmad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Ferreira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>123</td>\n",
       "      <td>32</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Stefano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>123</td>\n",
       "      <td>33</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Lovato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>123</td>\n",
       "      <td>1347</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Urs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  document  token           label        word\n",
       "0        0         7      9  B-NAME_STUDENT    Nathalie\n",
       "1        1         7     10  I-NAME_STUDENT       Sylla\n",
       "3        3         7    482  B-NAME_STUDENT    Nathalie\n",
       "4        4         7    483  I-NAME_STUDENT       Sylla\n",
       "6        6         7    741  B-NAME_STUDENT    Nathalie\n",
       "7        7         7    742  I-NAME_STUDENT       Sylla\n",
       "9        9        10      0  B-NAME_STUDENT       Diego\n",
       "10      10        10      1  I-NAME_STUDENT     Estrada\n",
       "11      11        10    464  B-NAME_STUDENT       Diego\n",
       "12      12        10    465  I-NAME_STUDENT     Estrada\n",
       "13      13        16      4  B-NAME_STUDENT    Gilberto\n",
       "14      14        16      5  I-NAME_STUDENT      Gamboa\n",
       "16      16        20      5  B-NAME_STUDENT       Sindy\n",
       "18      18        20      6  I-NAME_STUDENT      Samaca\n",
       "20      20        20    328  B-NAME_STUDENT      George\n",
       "21      21        20    330  B-NAME_STUDENT       Geoff\n",
       "22      22        56     12  B-NAME_STUDENT      Nadine\n",
       "23      23        56     13  I-NAME_STUDENT        Born\n",
       "24      24        86      6  B-NAME_STUDENT      Eladio\n",
       "26      26        86      7  I-NAME_STUDENT       Amaya\n",
       "27      27        93      0  B-NAME_STUDENT      Silvia\n",
       "28      28        93      1  I-NAME_STUDENT  Villalobos\n",
       "31      31       104      7  B-NAME_STUDENT          Dr\n",
       "32      32       104      8  B-NAME_STUDENT       Sakir\n",
       "34      34       104      9  I-NAME_STUDENT       Ahmad\n",
       "35      35       112      5  B-NAME_STUDENT   Francisco\n",
       "36      36       112      6  I-NAME_STUDENT    Ferreira\n",
       "37      37       123     32  B-NAME_STUDENT     Stefano\n",
       "38      38       123     33  I-NAME_STUDENT      Lovato\n",
       "39      39       123   1347  B-NAME_STUDENT         Urs"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reverse the transformation done by converttokenstodebert\n",
    "positions = []\n",
    "for i,pred in enumerate(predictions):\n",
    "    \n",
    "    # where there is a positive target\n",
    "    mask_ = pred[0,1:-1]!=12\n",
    "    \n",
    "    # row_id: initialize the column with zeros, then we set it equal to the index.\n",
    "    # document: document number from the 'document' column.\n",
    "    # token: token position that we know thanks to the mask calculated in the transformation.\n",
    "    positions = positions + [[0, test.iloc[i].document, test.iloc[i]['mask'][j],unique_labels[pred[0,j+1].item()], test.iloc[i].tokens[test.iloc[i]['mask'][j]]] for j,pos in enumerate(mask_) if pos]\n",
    "    \n",
    "\n",
    "submit = pd.DataFrame(positions,columns=submissions.columns.tolist()+['word']).drop_duplicates()\n",
    "submit.row_id = submit.index\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ae0011e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:38:42.003971Z",
     "iopub.status.busy": "2024-04-23T16:38:42.003105Z",
     "iopub.status.idle": "2024-04-23T16:38:42.011552Z",
     "shell.execute_reply": "2024-04-23T16:38:42.010822Z"
    },
    "papermill": {
     "duration": 0.3205,
     "end_time": "2024-04-23T16:38:42.013564",
     "exception": false,
     "start_time": "2024-04-23T16:38:41.693064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit[['row_id','document','token','label']].to_csv('submission.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "336b0b91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T16:38:42.646376Z",
     "iopub.status.busy": "2024-04-23T16:38:42.645984Z",
     "iopub.status.idle": "2024-04-23T16:38:42.660443Z",
     "shell.execute_reply": "2024-04-23T16:38:42.659521Z"
    },
    "papermill": {
     "duration": 0.330443,
     "end_time": "2024-04-23T16:38:42.662405",
     "exception": false,
     "start_time": "2024-04-23T16:38:42.331962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>482</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>483</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>741</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>742</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>464</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>465</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>328</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>330</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>104</td>\n",
       "      <td>8</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>123</td>\n",
       "      <td>32</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>123</td>\n",
       "      <td>33</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>123</td>\n",
       "      <td>1347</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  document  token           label\n",
       "0        0         7      9  B-NAME_STUDENT\n",
       "1        1         7     10  I-NAME_STUDENT\n",
       "3        3         7    482  B-NAME_STUDENT\n",
       "4        4         7    483  I-NAME_STUDENT\n",
       "6        6         7    741  B-NAME_STUDENT\n",
       "7        7         7    742  I-NAME_STUDENT\n",
       "9        9        10      0  B-NAME_STUDENT\n",
       "10      10        10      1  I-NAME_STUDENT\n",
       "11      11        10    464  B-NAME_STUDENT\n",
       "12      12        10    465  I-NAME_STUDENT\n",
       "13      13        16      4  B-NAME_STUDENT\n",
       "14      14        16      5  I-NAME_STUDENT\n",
       "16      16        20      5  B-NAME_STUDENT\n",
       "18      18        20      6  I-NAME_STUDENT\n",
       "20      20        20    328  B-NAME_STUDENT\n",
       "21      21        20    330  B-NAME_STUDENT\n",
       "22      22        56     12  B-NAME_STUDENT\n",
       "23      23        56     13  I-NAME_STUDENT\n",
       "24      24        86      6  B-NAME_STUDENT\n",
       "26      26        86      7  I-NAME_STUDENT\n",
       "27      27        93      0  B-NAME_STUDENT\n",
       "28      28        93      1  I-NAME_STUDENT\n",
       "31      31       104      7  B-NAME_STUDENT\n",
       "32      32       104      8  B-NAME_STUDENT\n",
       "34      34       104      9  I-NAME_STUDENT\n",
       "35      35       112      5  B-NAME_STUDENT\n",
       "36      36       112      6  I-NAME_STUDENT\n",
       "37      37       123     32  B-NAME_STUDENT\n",
       "38      38       123     33  I-NAME_STUDENT\n",
       "39      39       123   1347  B-NAME_STUDENT"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit[['row_id','document','token','label']]"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "datasetId": 2210196,
     "sourceId": 3693646,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 164766955,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2256.175783,
   "end_time": "2024-04-23T16:38:45.403893",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-23T16:01:09.228110",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
